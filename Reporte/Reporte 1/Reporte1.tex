\documentclass[12pt, letterpaper]{article}

% --- Paquetes de Configuración ---
\usepackage[utf8]{inputenc}
\usepackage[spanish, es-tabla]{babel} 
\usepackage{geometry}
\geometry{left=2.5cm, right=2.5cm, top=2.5cm, bottom=2.5cm}

% --- Paquetes para Elementos Visuales ---
\usepackage{graphicx} 
\usepackage{booktabs}
\usepackage{float}
\usepackage{subcaption}

% --- Información del Título ---
\title{\textbf{Informe de Avance: Procesamiento y Análisis de Datos}}
\author{Ricardo Esteban Lopera Vasco}
\date{\today}

\begin{document}

% Portada
\maketitle  
\newpage

% Tabla de Contenidos
\tableofcontents
\newpage

% -----------------------------------------------------------------
\section{Introducción y Objetivos}
El propósito de este informe es documentar la integridad y calidad de los datos recolectados para el proyecto, además de detallar los avances realizados en el \textbf{desarrollo} de modelos y los análisis preliminares.  

Los objetivos específicos de este reporte son:
\begin{itemize}
    \item Describir los avances en los modelos y análisis realizados hasta la fecha.   
    \item Presentar las métricas descriptivas preliminares obtenidas.
    \item Identificar y categorizar los errores sistemáticos en la captura de datos.
\end{itemize}





% -----------------------------------------------------------------
\section{Descripción del Conjunto de Datos}
La fuente de información consta de un conjunto de datos distribuido en 15 hojas, las cuales contienen entre 230 y 240 registros de plantas. El conjunto incluye 2150 variables correspondientes a longitudes de onda en el rango de 350 nm a 2500 nm.
Para \textbf{realizar} el análisis, se importaron las hojas como \textit{dataframes} individuales.

\begin{table}[h]
    \centering
    \caption{Diccionario de Variables Principales}
    \begin{tabular}{l l p{6.5cm}}
    \toprule
    \textbf{Variable} & \textbf{Tipo de Dato} & \textbf{Descripción} \\
    \midrule
    Tratamiento & Cadena (str) & Nombre del estrés aplicado a la planta. \\
    {[$350-2500$ nm]} & Numérico (Float) & Indica la reflectancia en cada longitud de onda. \\
    Planta & Numérico (Int) & Identificador único de cada planta (rango 1 a 30). \\
    \bottomrule
    \end{tabular}
\end{table}

Todas las muestras se dividen en 8 clases, las cuales representan distintos tipos de estrés aplicados a las plantas. El \textbf{número} de muestras por clase \textbf{se detalla a continuación}:

\begin{table}[h]
    \centering
    \caption{Distribución de Clases en el Conjunto de Datos}
    \begin{tabular}{l c}
    \toprule
    \textbf{Clase} & \textbf{Número de Muestras} \\
    \midrule
    E\_Hidrico   &   478 \\
    Control      &   461 \\
    Fusarium     &   448 \\
    Fus\_EH\_Ral   &   440 \\
    Ral\_EH      &   436 \\
    Fus\_EH      &   432 \\
    Ralstonia    &   428 \\
    Ral\_Fus     &   412 \\
    \bottomrule
    \end{tabular}
\end{table}

% -----------------------------------------------------------------







\section{Problemáticas Identificadas en los Datos}
Los \textbf{problemas} evidenciados en el conjunto de datos se clasifican en las siguientes categorías:

\subsection{Datos Faltantes}

Se identificaron valores faltantes en varias hojas; \textbf{particularmente}, existen dos casos críticos:
\begin{itemize}
    \item \textbf{Hoja 0 (Día 0):} En cada hoja \textbf{debería haber} 240 registros (30 plantas por tratamiento); sin embargo, en la hoja 0 faltan las 30 plantas correspondientes a \textbf{Fus\_EH}.
    \item \textbf{Hoja 15 (Día 15):} En la hoja falta el 29.2\% de los datos, \textbf{correspondientes} a: 12 datos de \textbf{Ralstonia}, 23 de \textbf{Ral\_EH}, 1 de \textbf{Fus\_EH} y 4 de \textbf{Fus\_EH\_Ral}.
\end{itemize}

En el resto de las hojas, el porcentaje de datos faltantes es inferior al 1\%, por lo cual no se considera crítico para el análisis. Sin embargo, se resalta que en cada hoja \textbf{se observan} inconsistencias y datos faltantes. 

\subsection{Datos No Etiquetados}

De las 15 hojas analizadas, se encontraron 10 hojas (66.6\% del total) sin la etiqueta "Planta"; \textbf{únicamente} las hojas 6, 7, 8, 12 y 13 poseen esta etiqueta. Estas etiquetas son cruciales para el entrenamiento supervisado, pues conocer el \textbf{número} de la planta es necesario para identificar cada muestra de manera única y \textbf{generar} conjuntos de entrenamiento y prueba \textbf{disjuntos} (sin solapamiento).

Es importante resaltar que esta etiqueta del \textbf{número} de planta no se puede inferir de las otras hojas, ya que, debido a la falta de uniformidad en el \textbf{número} de datos por hoja, no es posible realizar un mapeo directo entre las hojas que poseen la etiqueta y las que no.

\subsection{Inconsistencias en las Etiquetas de Clase}

En las hojas 4 y 10 se encontraron \textbf{dos} datos que no poseen etiqueta de "Tratamiento". \textbf{Tampoco existe} un registro \textbf{guía} de la \textbf{categoría} a la que podrían pertenecer estas muestras, lo cual dificulta su clasificación y uso en el entrenamiento de modelos supervisados.

\begin{figure}[H]
        \centering 
        \includegraphics[width=0.8\textwidth]{Imagenes/HOJA0.png} 
        \caption{Evidencia hoja 0 con columna "Planta" faltante} 
        \label{fig:missing_treatment}
\end{figure}









\section{Avances en el Procesamiento}
Hasta la fecha, se han completado las fases de ingestión, procesamiento de datos y \textbf{desarrollo} preliminar de modelos. A continuación, se detallan las observaciones clave:

\subsection{PCA y Reducción de Dimensionalidad}
Uno de los \textbf{principales desafíos} encontrados para el análisis y el \textbf{desarrollo} de modelos fue la alta dimensionalidad del conjunto de datos. Se aplicó Análisis de Componentes Principales (PCA) para reducir la dimensionalidad y se encontró que las primeras 3 componentes explican, en promedio, el 96.68\% de la varianza total; sin embargo, existen \textit{dataframes} donde el porcentaje de \textbf{varianza explicada} varía significativamente.

\begin{table}[h]
    \centering
    \caption{Varianza total explicada por el PCA (3 componentes) para cada subconjunto de datos.}
    \label{tab:pca_variance_3comp}
    \begin{tabular}{l c}
    \toprule
    \textbf{Modelo (\textit{DataFrame})} & \textbf{Varianza Explicada (\%)} \\
    \midrule
    df0 & 95.03\% \\
    df1 & 89.76\% \\
    df2 & 97.47\% \\
    df3 & 91.96\% \\
    df4 & 90.82\% \\
    df5 & 93.50\% \\
    df6 & 95.76\% \\
    df7 & 98.42\% \\
    df8 & 99.28\% \\
    df9 & 99.09\% \\
    df10 & 99.34\% \\
    df11 & 99.14\% \\
    df12 & 99.40\% \\
    df13 & 98.91\% \\
    df14 & 99.52\% \\
    df15 & 99.43\% \\
    \bottomrule
    \end{tabular}
\end{table}

Lo anterior demuestra que, aun reduciendo significativamente el número de dimensiones, se preserva una alta proporción de la varianza original. Esto garantiza la representatividad de los datos reducidos, asegurando que el entrenamiento de los modelos subsiguientes sea robusto y consistente con la estructura subyacente de la información.

\begin{figure}[H]
        \centering 
        \includegraphics[width=0.8\textwidth]{Imagenes/PCA results.png} 
        \caption{Resultados del PCA en el día 7} 
        \label{fig:pca_results} 
\end{figure}

\subsection{Balanceo algorítmico de datos vs. Balanceo estadístico}
El conjunto de datos presenta un desbalance de clases significativo, donde la clase minoritaria (plantas sanas) representa únicamente el 12\% del total de las muestras. Con el objetivo de mitigar este sesgo, se evaluaron estrategias de ponderación algorítmica (ajuste de pesos mediante el hiperparámetro \textit{balanced}) y técnicas de generación de datos sintéticos (SMOTE y ADASYN). 

Los resultados experimentales demostraron que las técnicas de sobremuestreo estadístico incrementaron el rendimiento de los modelos entre un 7\% y un 11\% en las métricas de exactitud (\textit{accuracy}) y sensibilidad (\textit{recall}). En contraste, la ponderación algorítmica no arrojó mejoras estadísticamente significativas. En consecuencia, se seleccionaron las técnicas de balanceo estadístico para las fases subsiguientes, debido a que proporcionaron una mayor estabilidad en la convergencia y optimizaron la identificación de la clase sana. 

\begin{figure}[H]
        \centering 
        \includegraphics[width=1\textwidth]{Imagenes/SMOTE_Report.png} 
        \caption{Reporte SMOTE para el día 2} 
        \label{fig:smote_report} 
\end{figure}


\subsection{Elección del Orden de Reducción y Balanceo}

Se evaluó el orden de aplicación de las técnicas de reducción de dimensionalidad (PCA) y balanceo estadístico (SMOTE) para determinar su impacto en el rendimiento del modelo. \textbf{Se compararon dos enfoques}: aplicar PCA antes de SMOTE y aplicar SMOTE antes de PCA. Los resultados indicaron que aplicar PCA \textbf{previo a} SMOTE condujo a una mejora significativa en las métricas de desempeño del modelo final, incluyendo un aumento del 6\% en la exactitud y un 8\% en la sensibilidad. 

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Imagenes/PCA_SMOTE.png}
        \caption{PCA $\rightarrow$ SMOTE (Exactitud: 91.00\%)}
        \label{fig:pca_before_smote}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.48\textwidth}
        \centering
        \includegraphics[width=\textwidth]{Imagenes/SMOTE_PCA.png}
        \caption{SMOTE $\rightarrow$ PCA (Exactitud: 88.1\%)}
        \label{fig:smote_before_pca}
    \end{subfigure}
    \caption{Comparación del rendimiento del modelo según el orden de aplicación de PCA y SMOTE.}
    \label{fig:pca_smote_comparison}
\end{figure}

Este enfoque permitió que SMOTE generara datos sintéticos en un espacio de menor dimensionalidad, lo que facilitó una mejor representación de la distribución de las clases y redujo el riesgo de sobreajuste. En contraste, aplicar SMOTE antes de PCA resultó en una menor calidad de los datos sintéticos generados, afectando negativamente el rendimiento del modelo. Por lo tanto, se concluyó que la secuencia óptima es aplicar PCA antes de SMOTE para maximizar la eficacia del balanceo estadístico en conjuntos de datos de alta dimensionalidad.

Una justificación adicional para esta elección es que, al reducir la dimensionalidad primero, se eliminan características redundantes y ruido, lo que permite que SMOTE opere en un espacio más limpio y representativo. Esto mejora la calidad de los datos sintéticos generados, ya que SMOTE puede enfocarse en las características más relevantes para la clasificación, evitando la generación de muestras que no reflejen adecuadamente la distribución real de las clases. En resumen, aplicar PCA antes de SMOTE no solo optimiza el rendimiento del modelo, sino que también mejora la integridad y representatividad de los datos sintéticos generados.

A continuación, se presentan los resultados comparativos entre ambos enfoques para cada uno de los modelos entrenados por \textbf{día}:

\begin{figure}[H]
        \centering 
        \includegraphics[width=0.8\textwidth]{Imagenes/ORDER.png} 
        \caption{Comparación de modelos PCA-SMOTE vs. SMOTE-PCA} 
        \label{fig:comparison_models}
\end{figure}

\section{Arquitectura del Modelo Principal}

La arquitectura del modelo propuesto se estructura en dos niveles: un conjunto de modelos base (Nivel 1) y un meta-modelo de ensamblaje (Nivel 2).

El Nivel 1 consta de 15 clasificadores independientes, entrenados específicamente para los datos de cada día. Cada modelo base consiste en una Regresión Logística implementada mediante el siguiente \textit{pipeline}:

\begin{itemize} 
    \item Reducción de dimensionalidad con PCA. 
    \item Sobremuestreo sintético de la clase minoritaria con SMOTE. 
    \item Ajuste de hiperparámetros de la Regresión Logística vía GridSearchCV. 
\end{itemize}

Se optó por esta arquitectura debido a su equilibrio entre simplicidad y rendimiento. En pruebas preliminares, algoritmos de mayor complejidad (p. ej., Random Forest, SVM, XGBoost y Bagging) no ofrecieron ventajas significativas en las métricas de evaluación.

El Nivel 2 es un meta-modelo que integra las predicciones generadas por los 15 modelos base. Actualmente, se utiliza una Regresión Logística que pondera las salidas del Nivel 1, considerando el desempeño histórico y el día correspondiente a cada modelo. Se encuentra en fase de experimentación el uso de arquitecturas alternativas para este ensamblador (incluyendo redes neuronales), aunque hasta la fecha no se han observado mejoras sustanciales en el rendimiento.

\begin{figure}[H]
    \centering 
    \includegraphics[width=0.8\textwidth]{Imagenes/MODEL.png} 
    \caption{Arquitectura del Modelo} 
    \label{fig:ensemble_model}
\end{figure}


\section{Transformada de Fourier espacial 2D}

Como parte de la estrategia experimental para optimizar el rendimiento del modelo, se implementó la Transformada de Fourier en 2D (2D-FFT) con el objetivo de analizar las características frecuenciales de las señales espectrales. Esta técnica permite la identificación de patrones latentes y tendencias no evidentes en el dominio espacial, facilitando, teóricamente, la extracción de descriptores discriminantes para la clasificación. Mediante la aplicación de la 2D-FFT, las señales espectrales fueron transformadas al dominio de la frecuencia, permitiendo aislar componentes periódicas y atenuar el ruido de alta frecuencia.

Las salidas generadas por la 2D-FFT se interpretan como tensores de imágenes, los cuales se descomponen en los siguientes canales:

\begin{itemize}
    \item \textbf{Canal de Magnitud:} Representa la amplitud de las frecuencias presentes en la señal. Cabe destacar que, para la generación de las imágenes de este canal, se aplicó una transformación logarítmica de la forma $\log(1+x)$. Este preprocesamiento fue indispensable para comprimir el rango dinámico y resaltar características estructurales tenues, evitando así la generación de imágenes planas o con pérdida de información en las frecuencias de menor intensidad.
    \item \textbf{Canal de Potencia:} Indica la densidad espectral de energía asociada a cada frecuencia, calculada como el cuadrado de la magnitud ($P = |Magnitud|^2$).
    \item \textbf{Canal de Fase:} Describe el desplazamiento angular de las ondas componentes en el dominio de la frecuencia.
    \item \textbf{Componente Real:} Corresponde a la parte real de los números complejos resultantes de la Transformada de Fourier.
\end{itemize}

La visualización de estos canales se presenta a continuación:

\begin{figure}[H]
    \centering 
    \includegraphics[width=0.8\textwidth]{Imagenes/FFT_channels.png} 
    \caption{Canales resultantes de la descomposición mediante Transformada de Fourier en 2D.} 
    \label{fig:fft_channels}
\end{figure}

El experimento se centró en evaluar si los descriptores extraídos mediante la 2D-FFT aumentaban la capacidad discriminante del modelo; específicamente, se analizó el comportamiento de los canales de magnitud y potencia al ser utilizados como vectores de entrada.

En las gráficas de magnitud se observaron, en ciertas muestras, diferencias cualitativas notables entre los espectros de plantas sanas y enfermas. Esto sugería inicialmente que dichas características frecuenciales podrían favorecer la clasificación. No obstante, se determinó que estas diferencias no son consistentes en la totalidad del conjunto de datos. Un ejemplo de este fenómeno se ilustra en la siguiente figura, correspondiente a una planta enferma del día 13:

\begin{figure}[H]
    \centering 
    \includegraphics[width=0.8\textwidth]{Imagenes/FFT_healthy_vs_infected.png} 
    \caption{Análisis comparativo de la 2D-FFT entre especímenes sanos e infectados.} 
    \label{fig:fft_comparison}
\end{figure}

Pese a las observaciones visuales preliminares, los resultados experimentales no demostraron una mejora estadísticamente significativa en el rendimiento del modelo al incorporar las características de la 2D-FFT. Las métricas de evaluación (exactitud, precisión y sensibilidad) no presentaron incrementos sustanciales respecto al modelo base entrenado con las señales espectrales en el dominio original.

Metodológicamente, los datos fueron sometidos primero a un balanceo de clases mediante la técnica SMOTE. Posteriormente, se les aplicó la Transformada de Fourier en 2D y, finalmente, se entrenó una Red Neuronal Convolucional (CNN) utilizando los canales de magnitud y potencia resultantes como tensores de entrada.



\subsection{Arquitectura de la Red Neuronal Convolucional}

La arquitectura del CNN implementada consta de dos componentes principales: una serie de capas convolucionales para la extracción de características y capas completamente conectadas para la clasificación final. A continuación se detalla cada componente:

\subsubsection{Bloque de Capas Convolucionales}

El modelo procesa imágenes RGB de entrada (3 canales) mediante cuatro bloques convolucionales secuenciales:

\textbf{Bloque 1:}
\begin{itemize}
    \item Capa Convolucional: 16 filtros de 3$\times$3 con padding=1
    \item Normalización por Lotes (BatchNorm2d)
    \item Función de Activación: ReLU
    \item Max Pooling: 2$\times$2 (reduce dimensiones espaciales a la mitad)
\end{itemize}

\textbf{Bloque 2:}
\begin{itemize}
    \item Capa Convolucional: 32 filtros de 3$\times$3 con padding=1
    \item Normalización por Lotes (BatchNorm2d)
    \item Función de Activación: ReLU
    \item Max Pooling: 2$\times$2
\end{itemize}

\textbf{Bloque 3:}
\begin{itemize}
    \item Capa Convolucional: 64 filtros de 3$\times$3 con padding=1
    \item Normalización por Lotes (BatchNorm2d)
    \item Función de Activación: ReLU
    \item Max Pooling: 2$\times$2
    \item Dropout2d: 25\% (regularización espacial)
\end{itemize}

\textbf{Bloque 4:}
\begin{itemize}
    \item Capa Convolucional: 128 filtros de 3$\times$3 con padding=1
    \item Normalización por Lotes (BatchNorm2d)
    \item Función de Activación: ReLU
    \item Global Average Pooling: AdaptiveAvgPool2d(1$\times$1) (convierte el mapa de características en un vector de 128 elementos)
\end{itemize}

\subsubsection{Bloque de Capas Completamente Conectadas}

Tras la extracción de características, el vector resultante se procesa mediante:

\begin{itemize}
    \item Aplanamiento (Flatten): Convierte el tensor 128$\times$1$\times$1 en un vector de 128 elementos
    \item Capa Densa 1: 128 $\rightarrow$ 64 neuronas
    \item Función de Activación: ReLU
    \item Dropout: 50\% (alto dropout debido al tamaño reducido del dataset)
    \item Capa de Salida: 64 $\rightarrow$ 2 neuronas (clasificación binaria: Sana/Infectada)
\end{itemize}

\subsubsection{Características de Diseño}

La arquitectura implementa varias técnicas de regularización para prevenir el sobreajuste:

\begin{enumerate}
    \item \textbf{Normalización por Lotes:} Aplicada en cada bloque convolucional para estabilizar y acelerar el entrenamiento.
    \item \textbf{Dropout Espacial:} 25\% en el tercer bloque convolucional para reducir correlaciones espaciales.
    \item \textbf{Dropout Denso:} 50\% en la capa completamente conectada, especialmente alto debido al tamaño limitado del conjunto de datos.
    \item \textbf{Global Average Pooling:} Reduce drásticamente el número de parámetros en comparación con capas completamente conectadas de gran tamaño, minimizando el riesgo de sobreajuste.
\end{enumerate}

El número total de parámetros entrenables del modelo es relativamente bajo en comparación con arquitecturas CNN estándar (ResNet, VGG), lo cual es apropiado para el tamaño del dataset disponible. La arquitectura progresiva (16$\rightarrow$32$\rightarrow$64$\rightarrow$128 filtros) permite capturar características de diferentes niveles de abstracción, desde bordes y texturas básicas hasta patrones complejos específicos de las plantas infectadas.

\subsubsection{Entrenamiento y Optimización}

El modelo se entrenó utilizando los siguientes hiperparámetros:

\begin{itemize}
    \item \textbf{Función de Pérdida:} CrossEntropyLoss
    \item \textbf{Optimizador:} Adam con tasa de aprendizaje de $1\times10^{-4}$
    \item \textbf{Batch Size:} 16 muestras
    \item \textbf{Épocas Máximas:} 50
    \item \textbf{Early Stopping:} Se detiene el entrenamiento si no hay mejora en la exactitud de validación durante 5 épocas consecutivas
    \item \textbf{División de Datos:} 80\% entrenamiento, 10\% validación, 10\% prueba
\end{itemize}

A pesar de este enfoque, los resultados no indicaron mejoras significativas en las métricas de rendimiento del modelo en comparación con el modelo base de Regresión Logística con PCA.

\subsection{Resultados modelos de magnitud}

Para la magnitud, los resultados obtenidos fueron los siguientes:










% -----------------------------------------------------------------

\end{document}